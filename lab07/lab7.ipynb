{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BknZ4N68PhQ"
   },
   "source": [
    "# Lab 7 - Model Optimization for Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objBFjUrnUPy"
   },
   "source": [
    "## 1. Evaluation mode - Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foBG5lP-JCuH"
   },
   "source": [
    "#### Load the model and tokenize sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336,
     "referenced_widgets": [
      "6bd7e317558f4fe49e115bb1cf1cc687",
      "e3a6d589d8a04b6eb1d9e3a6d0d5e72e",
      "df55187e97ee421ca70b50a92ec49da9",
      "cacca0f04c4143ee98d2446c2d93a32d",
      "70b05bab950d4ed49800f203128d6658",
      "34f29e63a0a7407392a2b6bcca9ac218",
      "ead478ef27e245f3abda293ec6bbad34",
      "2fafaeed688444e68783845e3e4746d7",
      "a3b85d19946d4bf3a5c86921f496dfa3",
      "59e7cde698554d058762c47e8604bf78",
      "a0aeb0da28884559a272baa62c5cafe0",
      "170294604c5d4a2cb206a6ab5c1c5642",
      "6e6a9ecb5bbe4d5b9ba2a88f18037ace",
      "a9c45abd114f42909257c41381f172b0",
      "40d66fa92f084e29b055add1ce5682c8",
      "33a7d60640c147088c708b0add2688b2",
      "6558010fe9ab47ab9a989adde9b807e5",
      "8bfcbd335d03430792c502ed76610935",
      "a725900520cc4079ab089ea224947cde",
      "523aa6909f3148a1a6657d4132295491",
      "15f6d2cbef09479c953aa503aaaf4c7d",
      "1b94d56dea114d06bcf821dd0a005866",
      "d4c4cd6814974c7bb034e91c6fbbd4a0",
      "e7992d3659144c57b986e0dd042c9665",
      "4664f0cc7cac4322a8f25e1e6fca6705",
      "a8ae023f80f64dcb8e34f179df4392cb",
      "254d499cf20243f9a497e79a79510da3",
      "495be958ba3342fe878c6feefad0849c",
      "41e4e498c07e46eab9abbed4a88eba3f",
      "6296b8bf39e247feb9faf52449d2f4a6",
      "36ccc56f32914857b6d8bf3b39dcaa73",
      "0159ad33dbbe43ca8fc6096670f03cb6",
      "0cbbda432c5144d3b30a8ee1b633eb21",
      "e1a0aa7fbc4b44c0a243a11b582a3515",
      "eaffed41a00d4cd68f194f4ddb4539bd",
      "7b2f719222c84b4c92f8bc2c8ce679b3",
      "12a234c6c0bf4c3987d097cf0f7767a3",
      "596ec35ac62f4b97ae9d7310bfe5f7f0",
      "5267a9c4e6394a7f9edbff6660e43f14",
      "58e48aa8b2d74b31a28edd3b9f5ed107",
      "303e9ff1399f482fb5e4f73a0a598a8a",
      "02d164585b814294bdc4675592dd2880",
      "ab52630fa2994dfe82e6480c94828289",
      "48920fdbd59c44f58d8b9d7b6d6096a8",
      "a243ae54dfb34b2985b0b4a3da523a8f",
      "55414364af384b75af725fce2a5ab594",
      "ad9d34d05f1c46269751082fbcd35227",
      "4ef8039541ca46448df43e1a516a70e1",
      "5ba56bf079e44b799fa8efec11ffb302",
      "4de2e289ceec4ab3bbe76366ff673b62",
      "507db3264a9845689af9b0cc5d6abbf0",
      "72a88846744243bf94635ea1310f7b9d",
      "54bb2daa3156465a8adf02937a76ef0c",
      "c3994c53068f46ab96bc1d0681d6030e",
      "0c620464c043466eaf80ec9c31d0fb75",
      "7c4156c884da46fba3d404ffddbca8a9",
      "97424668027d43b8ac6b7bf0314d667b",
      "f922676468b4466eb73b33706f030101",
      "22fee1031b8d4ca9a77a23d813fd31ff",
      "f2a4018b56d048b8b5fa60f91b7e02c1",
      "4106d763fa1f43a8bf78d49ab6d9f302",
      "9ce5926d4d0e45de8e0e33f70bafd104",
      "e6c1e6b857e341989582ccc898679b00",
      "52cd2df4f41e435b99ac88190fa824af",
      "dee930f1ee15454083c279eb16d33c9c",
      "540d70afdd4b4dc5b91129fc8e5c4efd"
     ]
    },
    "id": "Iv2l264t0DM7",
    "outputId": "1fbe8c20-52ee-4226-e85a-d1153c75739b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd7e317558f4fe49e115bb1cf1cc687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170294604c5d4a2cb206a6ab5c1c5642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c4cd6814974c7bb034e91c6fbbd4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a0aa7fbc4b44c0a243a11b582a3515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a243ae54dfb34b2985b0b4a3da523a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4156c884da46fba3d404ffddbca8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# load the model and tokenizer\n",
    "model_name = \"sentence-transformers/multi-qa-mpnet-base-cos-v1\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vOzVlblOpRym"
   },
   "outputs": [],
   "source": [
    "# sample text from: https://wolnelektury.pl/katalog/lektura/lalka-tom-pierwszy.html\n",
    "\n",
    "sample_text = \"\"\"\n",
    "Czuł w duszy dziwną pustkę, a na samym jej dnie coś, jakby kroplę piekącej goryczy. Żadnych sił, żadnych pragnień, nic, tylko tę kroplę tak małą, że jej niepodobna dojrzeć, a tak gorzką, że cały świat można by nią zatruć.\n",
    "\n",
    "„Chwilowa apatia, wyczerpanie, brak wrażeń… Za dużo myślę o interesach” — mówił.\n",
    "Stanął i patrzył. Dzień przedświąteczny i ładna pogoda wywabiły mnóstwo ludzi na bruk miejski. Sznur powozów i pstrokaty falujący tłum między Kopernikiem i Zygmuntem\n",
    "\n",
    "wyglądał jak stado ptaków, które właśnie w tej chwili unosiły się nad miastem dążąc ku północy.\n",
    "\n",
    "„Szczególna rzecz — mówił. — Każdy ptak w górze i każdy człowiek na ziemi wyobraża sobie, że idzie tam, dokąd chce. I dopiero ktoś stojący na boku widzi, że wszystkich razem pcha naprzód jakiś fatalny prąd, mocniejszy od ich przewidywań i pragnień. Może nawet ten sam, który unosi smugę iskier wydmuchniętych przez lokomotywę podczas nocy?… Błyszczą przez mgnienie oka, aby zgasnąć na całą wieczność, i to nazywa się życiem.\n",
    "\n",
    "    Mijają ludzkie pokolenia\n",
    "    Jak fale, gdy wiatr morzem zmąci;\n",
    "    I nie masz godów ich pamięci,\n",
    "    I nie masz bólów ich wspomnienia.\n",
    "\n",
    "Gdzie ja to czytałem?… Wszystko jedno.”\n",
    "\n",
    "„Oto miniatura kraju — myślał — w którym wszystko dąży do spodlenia i wytępienia rasy. Jedni giną z niedostatku, drudzy z rozpusty. Praca odejmuje sobie od ust, ażeby karmić niedołęgów; miłosierdzie hoduje bezczelnych próżniaków, a ubóstwo nie mogące zdobyć się na sprzęty otacza się wiecznie głodnymi dziećmi, których największą zaletą jest wczesna śmierć.\n",
    "Tu nie poradzi jednostka z inicjatywą, bo wszystko sprzysięgło się, ażeby ją spętać i zużyć w pustej walce — o nic.”\n",
    "\n",
    "Gdy Wokulski zadzwonił do mieszkania lekarza, ten właśnie był zajęty gatunkowaniem włosów rozmaitych osobników rasy słowiańskiej, germańskiej i semickiej i przy pomocy mikroskopu mierzył dłuższe i krótsze średnice ich przekrojów.\n",
    "\n",
    "— A, jesteś?… — rzekł do Wokulskiego odwracając głowę. — Nałóż sobie fajkę, jeżeli chcesz, i kładź się na kanapie, jeżeli się zmieścisz.\n",
    "\n",
    "Gość zapalił fajkę i położył się, jak mu kazano, doktór robił swoje. Przez pewien czas obaj milczeli, wreszcie odezwał się Wokulski:\n",
    "\n",
    "— Powiedz mi: czy medycyna zna taki stan umysłu, w którym człowiekowi wydaje się, że jego rozproszone dotychczas wiadomości i… uczucia złączyły się jakby w jeden organizm?\n",
    "— Owszem. Przy ciągłej pracy umysłowej i dobrym odżywianiu mogą wytworzyć się w mózgu nowe komórki albo — skojarzyć się między sobą dawne. No i wówczas z rozmaitych departamentów\n",
    "\n",
    "mózgu i z rozmaitych dziedzin wiedzy tworzy się jedna całość.\n",
    "\n",
    "— A co znaczy taki stan umysłu, w którym człowiek obojętnieje dla śmierci, ale za to poczyna tęsknić do legend o życiu wiecznym?…\n",
    "\n",
    "— Obojętność dla śmierci — odpowiedział doktór — jest cechą umysłów dojrzałych, a pociąg do życia wiecznego — zapowiedzią nadchodzącej starości.\n",
    "\n",
    "Znowu umilkli. Gość palił fajkę, gospodarz kręcił się nad mikroskopem.\n",
    "\n",
    "— Czy myślisz — spytał Wokulski — że można… kochać kobietę w sposób idealny, nie pożądając jej?\n",
    "\n",
    "— Naturalnie. Jest to jedna z masek, w którą lubi przebierać się instynkt utrwalenia gatunku.\n",
    "\n",
    "— Instynkt — gatunek — instynkt utrwalenia czegoś i — utrwalenie gatunku!… — powtórzył Wokulski. — Trzy wyrazy, a cztery głupstwa.\n",
    "\n",
    "— Zrób szóste — odpowiedział doktór nie odejmując oka od szkła — i ożeń się.\n",
    "\n",
    "— Szóste?… — rzekł Wokulski podnosząc się na kanapie. — A gdzież piąte?\n",
    "\n",
    "— Piąte już zrobiłeś: zakochałeś się.\n",
    "\n",
    "— Ja?… W moim wieku?…\n",
    "\n",
    "— Czterdzieści pięć lat — to epoka ostatniej miłości, najgorszej — odpowiedział doktór.\n",
    "\n",
    "— Znawcy mówią, że pierwsza miłość jest najgorsza — szepnął Wokulski.\n",
    "— Nieprawda. Po pierwszej czeka cię sto innych, ale po setnej pierwszej — już nic. Żeń się; jedyny to ratunek na twoją chorobę.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GqLI5xk9HJgz"
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(sample_text, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuKnvKk2I7WM"
   },
   "source": [
    "#### Inference time for different inference modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JQ4hASEkIhwz"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjQRATXKJ9Ln"
   },
   "source": [
    "- No optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dw2Rl6ZwJ5zp",
    "outputId": "4e656594-e5a3-4cf0-f68d-13dd20907b47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2029865765571595"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for _ in range(100):\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "res_no_opt = (end - start) / 100\n",
    "res_no_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crWEg8F1KZQS"
   },
   "source": [
    "- eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tTAkYzC6KbFB",
    "outputId": "07edccac-2ef7-4e18-e6be-3a7b7d386dac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1169808459281922"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model.eval()\n",
    "for _ in range(100):\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "res_eval = (end - start) / 100\n",
    "res_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8V9-aVkSKjhm",
    "outputId": "e8b52180-f042-443d-d69c-30da62d91fbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0992486834526063"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(100):\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "res_no_grad = (end - start) / 100\n",
    "res_no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QuDrhGUEK7jm",
    "outputId": "c9f41dc4-e0f8-4854-aa70-0f231aa13a28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1085404634475708"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for _ in range(100):\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "end = time.time()\n",
    "res_infer = (end - start) / 100\n",
    "res_infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6M2cthbMOLS7"
   },
   "source": [
    "Speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "asG5zcGGOMT3",
    "outputId": "08214f2c-7f21-48eb-dcc9-1667e65ff450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " inference mode                     | speedup (baseline/mode)\n",
      "--------------------------------------------------------------\n",
      "model.eval()                        | 1.08x\n",
      "model.eval() + torch.no_grad()      | 1.09x\n",
      "model.eval() + inference_mode()     | 1.09x\n"
     ]
    }
   ],
   "source": [
    "print(f\"{' inference mode':35} | speedup (baseline/mode)\")\n",
    "print(\"-\" * 62)\n",
    "print(f\"{'model.eval()':35} | {res_no_opt / res_eval:.2f}x\")\n",
    "print(f\"{'model.eval() + torch.no_grad()':35} | {res_no_opt / res_no_grad:.2f}x\")\n",
    "print(f\"{'model.eval() + inference_mode()':35} | {res_no_opt / res_infer:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqhhopqELULQ"
   },
   "source": [
    "**Comment:** The results are slightly better for subsequent inference modes as compared to the non-optimised inference mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5_XlaIUQ6ZW"
   },
   "source": [
    "## PyTorch model compilation - Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zoy_hGrfP-8K",
    "outputId": "8f08aabb-d8e2-45ed-b0f5-81235f14711e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation and inference warm-up time: 38.24\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model.eval()\n",
    "compiled_model = torch.compile(model)\n",
    "\n",
    "# single inference\n",
    "compiled_model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = compiled_model(**inputs)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "comp_and_warmup = end - start\n",
    "print(f\"Compilation and inference warm-up time: {comp_and_warmup:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7Z9sdUxXdt-",
    "outputId": "715861ed-9b78-49f7-8fcb-1801d595397d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled model average inference time in inference mode: 1.43\n",
      "Compiled model speedup in inference mode: 0.84x\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# compiled_model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for _ in range(100):\n",
    "        outputs = compiled_model(**inputs)\n",
    "\n",
    "end = time.time()\n",
    "res_comp_infer = (end - start) / 100\n",
    "\n",
    "print(f\"Compiled model average inference time in inference mode: {res_comp_infer:.2f}\")\n",
    "print(f\"Compiled model speedup in inference mode: {res_no_opt / res_comp_infer:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otGbbsSsLp9T"
   },
   "source": [
    "**Comment:** For this task model compilaton did not improve inference time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6O8egKVRDWD"
   },
   "source": [
    "## Quantization - Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhvUdDNlYoYW"
   },
   "source": [
    "\"Another way to optimize a model is to quantize its weights, reducing its size, but also the precision.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1Q_TSyGmRG-W"
   },
   "outputs": [],
   "source": [
    "model = model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWaxisZFZ6Yi",
    "outputId": "f389da37-7693-48b2-882c-932d96cb1cac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2605189210.py:1: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  model_quantized = torch.ao.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)\n"
     ]
    }
   ],
   "source": [
    "model_quantized = torch.ao.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gsnMZ4YxZ6MN",
    "outputId": "f507e2c1-7480-48ac-d6a8-7e3a089f4c12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNetModel(\n",
      "  (embeddings): MPNetEmbeddings(\n",
      "    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
      "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): MPNetEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x MPNetLayer(\n",
      "        (attention): MPNetAttention(\n",
      "          (attn): MPNetSelfAttention(\n",
      "            (q): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (k): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (v): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (o): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (intermediate): MPNetIntermediate(\n",
      "          (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): MPNetOutput(\n",
      "          (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (relative_attention_bias): Embedding(32, 12)\n",
      "  )\n",
      "  (pooler): MPNetPooler(\n",
      "    (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "qHpHHG2vcHUM",
    "outputId": "c3895353-4049-40c7-efc4-35d22391ee1a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "YPn4kGtbcQ0b"
   },
   "outputs": [],
   "source": [
    "# saving both models\n",
    "torch.save(model.state_dict(), \"model.pt\")\n",
    "torch.save(model_quantized.state_dict(), \"model_quantized.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opIIzMtJeVuN"
   },
   "source": [
    "Model size comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yP4sR_t9dDUD",
    "outputId": "38e55d0e-96cd-4949-c7a5-ff78644268d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of normal model: 417.72 MB\n",
      "Size of quantized model: 173.10 MB\n"
     ]
    }
   ],
   "source": [
    "model_size_mb = os.path.getsize(\"model.pt\") / (1024**2)\n",
    "model_quantized_size_mb = os.path.getsize(\"model_quantized.pt\") / (1024**2)\n",
    "\n",
    "print(f\"Size of normal model: {model_size_mb:.2f} MB\")\n",
    "print(f\"Size of quantized model: {model_quantized_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLywXgN6L1oq"
   },
   "source": [
    "**Comment:** The quantized model takes up over two times less memory than the non-quantized model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTMy8Li5eSxD"
   },
   "source": [
    "Speedup comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3sCugJ37I0_C",
    "outputId": "cd44e091-7781-4312-eea9-735fdee847c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0660580229759216"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for _ in range(100):\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "res_origin_infer = (end - start) / 100\n",
    "res_origin_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vy6-fVZZeSY0",
    "outputId": "b41d4899-d2b0-489e-a857-9fd177056e61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model average inference time in inference mode: 0.87\n",
      "Quantized model speedup in inference mode: 1.22x\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model_quantized.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for _ in range(100):\n",
    "        outputs = model_quantized(**inputs)\n",
    "\n",
    "end = time.time()\n",
    "res_quant_infer = (end - start) / 100\n",
    "\n",
    "print(\n",
    "    f\"Quantized model average inference time in inference mode: {res_quant_infer:.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Quantized model speedup in inference mode: {res_origin_infer / res_quant_infer:.2f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42xZUf0oMHDr"
   },
   "source": [
    "**Comment:** Quantization also allowed for a substantial speedup comapred to the non-quantized model (both used in the inference_mode mode)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2YXylaPRJo8"
   },
   "source": [
    "## GPU optimization strategies - Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vu6abZ7-ROAX",
    "outputId": "8056f65d-1c0c-4e26-fc22-3f0be0dc2917"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "szOulTPqBnLE"
   },
   "outputs": [],
   "source": [
    "model_gpu = model.to(device)\n",
    "inputs_gpu = {k: v.to(device) for k, v in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aibzx9v8Ecm_",
    "outputId": "335222d3-9748-4860-84ca-0739d9667035"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  return torch._C._get_cublas_allow_tf32()\n",
      "W0105 21:42:26.078000 287 torch/_inductor/utils.py:1558] [0/1] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    }
   ],
   "source": [
    "model_gpu.eval()\n",
    "compiled_model_gpu = torch.compile(model_gpu)\n",
    "\n",
    "compiled_model_gpu.eval()\n",
    "with torch.inference_mode():\n",
    "    outputs = compiled_model_gpu(**inputs_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYHAvn6nB9EE",
    "outputId": "ed64f721-fa14-4295-b1b0-153f73258142"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Autotune Choices Stats:\n",
      "{\"num_choices\": 2, \"num_triton_choices\": 0, \"best_kernel\": \"bias_addmm\", \"best_time\": 0.27852800488471985}\n",
      "AUTOTUNE addmm(512x768, 512x768, 768x768)\n",
      "strides: [0, 1], [768, 1], [1, 768]\n",
      "dtypes: torch.float32, torch.float32, torch.float32\n",
      "  bias_addmm 0.2785 ms 100.0% \n",
      "  addmm 0.2908 ms 95.8% \n",
      "SingleProcess AUTOTUNE benchmarking takes 0.0987 seconds and 0.0002 seconds precompiling for 2 choices\n"
     ]
    }
   ],
   "source": [
    "# Enable CUDA Graphs for maximum throughput\n",
    "model_gpu.eval()\n",
    "compiled_model_with_cudagraphs = torch.compile(model_gpu, mode=\"max-autotune\")\n",
    "\n",
    "compiled_model_with_cudagraphs.eval()\n",
    "with torch.inference_mode():\n",
    "    outputs = compiled_model_with_cudagraphs(**inputs_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "LbXcGO6V_z3r"
   },
   "outputs": [],
   "source": [
    "# Enable max-autotune without CUDA Graphs for dynamic input shapes\n",
    "model_gpu.eval()\n",
    "compiled_model_dynamic = torch.compile(model_gpu, mode=\"max-autotune-no-cudagraphs\")\n",
    "\n",
    "compiled_model_dynamic.eval()\n",
    "with torch.inference_mode():\n",
    "    outputs = compiled_model_dynamic(**inputs_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaORbf5lFQt1"
   },
   "source": [
    "Inference time comparison for different compile modes and input sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VPivZO9HeFS"
   },
   "outputs": [],
   "source": [
    "def measure_inference_time(model, inputs, n_runs):\n",
    "    start = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for _ in range(n_runs):\n",
    "            _ = model(**inputs)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.synchronize()  # wait for GPU to finish work\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    return (end - start) / n_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd-tsEgoFqSC",
    "outputId": "84a96577-c773-4ec9-910a-57a3c24281e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03434568333625793"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_comp_gpu = measure_inference_time(compiled_model_gpu, inputs_gpu, 1000)\n",
    "res_comp_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUCJIRrAFLKY",
    "outputId": "fadf8ae7-d4ea-46e2-e162-cd626da9b1c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.035183266878128054"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_comp_cuda_gpu = measure_inference_time(\n",
    "    compiled_model_with_cudagraphs, inputs_gpu, 1000\n",
    ")\n",
    "res_comp_cuda_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4kDKDHRGPHN",
    "outputId": "55a45601-23bd-4fe1-82c6-8cc31dae2531"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03412899374961853"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_comp_dynamic_gpu = measure_inference_time(compiled_model_dynamic, inputs_gpu, 1000)\n",
    "res_comp_dynamic_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fmEUK34NK4w",
    "outputId": "69096626-d313-45b6-af22-9966d07c56d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference mode                                                    | time       | speedup (baseline/mode)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.compile()                                                   |       0.03 | -\n",
      "torch.compile() with mode=\"max-autotune\"                          |       0.04 | 0.98x\n",
      "torch.compile() with mode=\"max-autotune-no-cudagraphs\"            |       0.03 | 1.01x\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'inference mode':65} | {'time':10} | speedup (baseline/mode)\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"{'torch.compile()':65} | {res_comp_gpu:10.2f} | -\")\n",
    "print(\n",
    "    f\"{'torch.compile() with mode=\"max-autotune\"':65} | {res_comp_cuda_gpu:10.2f} | {res_comp_gpu / res_comp_cuda_gpu:.2f}x\"\n",
    ")\n",
    "print(\n",
    "    f\"{'torch.compile() with mode=\"max-autotune-no-cudagraphs\"':65} | {res_comp_dynamic_gpu:10.2f} | {res_comp_gpu / res_comp_dynamic_gpu:.2f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Brr9lyVNNaqs"
   },
   "source": [
    "**Comment:** The speedup for the graph optimized modes is not significant for the current input, possibly due to the overhead related to transferring data to the GPU?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMW9mcEw_k-A"
   },
   "source": [
    " \"CUDA Graphs become invalid when input dimensions change. - They are static by design.\"\n",
    " - \"The `max-autotune-no-cudagraphs` mode addresses this limitation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xl28piqJMVB",
    "outputId": "a77b71f6-deb8-4024-8ce9-aea383d5c82f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Autotune Choices Stats:\n",
      "{\"num_choices\": 2, \"num_triton_choices\": 0, \"best_kernel\": \"bias_addmm\", \"best_time\": 0.2131199985742569}\n",
      "AUTOTUNE addmm(347x768, 347x768, 768x768)\n",
      "strides: [0, 1], [768, 1], [1, 768]\n",
      "dtypes: torch.float32, torch.float32, torch.float32\n",
      "  bias_addmm 0.2131 ms 100.0% \n",
      "  addmm 0.2273 ms 93.8% \n",
      "SingleProcess AUTOTUNE benchmarking takes 0.0660 seconds and 0.0003 seconds precompiling for 2 choices\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.921022152900696"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5x shorter input\n",
    "short_text = sample_text[: len(sample_text) // 5]\n",
    "\n",
    "short_inputs = tokenizer(short_text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "short_inputs_gpu = {k: v.to(device) for k, v in short_inputs.items()}\n",
    "\n",
    "# a couple inference warm-up runs for each model\n",
    "measure_inference_time(compiled_model_gpu, short_inputs_gpu, 10)\n",
    "measure_inference_time(compiled_model_with_cudagraphs, short_inputs_gpu, 10)\n",
    "measure_inference_time(compiled_model_dynamic, short_inputs_gpu, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMi5McYGPX69",
    "outputId": "690f3bcc-121f-4aa5-dfbc-d2c98426d528"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference mode                                                    | time       | speedup (baseline/mode)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.compile()                                                   |       0.03 | -\n",
      "torch.compile() with mode=\"max-autotune\"                          |       0.03 | 1.06x\n",
      "torch.compile() with mode=\"max-autotune-no-cudagraphs\"            |       0.03 | 1.07x\n"
     ]
    }
   ],
   "source": [
    "res_comp_gpu_short = measure_inference_time(compiled_model_gpu, short_inputs_gpu, 1000)\n",
    "\n",
    "res_comp_cuda_gpu_short = measure_inference_time(\n",
    "    compiled_model_with_cudagraphs, short_inputs_gpu, 1000\n",
    ")\n",
    "\n",
    "res_comp_dynamic_gpu_short = measure_inference_time(\n",
    "    compiled_model_dynamic, short_inputs_gpu, 1000\n",
    ")\n",
    "\n",
    "print(f\"{'inference mode':65} | {'time':10} | speedup (baseline/mode)\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"{'torch.compile()':65} | {res_comp_gpu_short:10.2f} | -\")\n",
    "print(\n",
    "    f\"{'torch.compile() with mode=\"max-autotune\"':65} | {res_comp_cuda_gpu_short:10.2f} | {res_comp_gpu_short / res_comp_cuda_gpu_short:.2f}x\"\n",
    ")\n",
    "print(\n",
    "    f\"{'torch.compile() with mode=\"max-autotune-no-cudagraphs\"':65} | {res_comp_dynamic_gpu_short:10.2f} | {res_comp_gpu_short / res_comp_dynamic_gpu_short:.2f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aLrCo_eO5wY"
   },
   "source": [
    "**Comment:** For shorter input there seems to be a slight speedup for CUDA graphs compared to the torch compiled-only model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVatGYBcU-C2",
    "outputId": "c2a96de4-13f6-4d2b-f6bf-521434459be6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04739067554473877"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5x longer input\n",
    "long_text = sample_text * 5\n",
    "\n",
    "long_inputs = tokenizer(long_text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "long_inputs_gpu = {k: v.to(device) for k, v in long_inputs.items()}\n",
    "\n",
    "measure_inference_time(compiled_model_gpu, long_inputs_gpu, 10)\n",
    "measure_inference_time(compiled_model_with_cudagraphs, long_inputs_gpu, 10)\n",
    "measure_inference_time(compiled_model_dynamic, long_inputs_gpu, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DLKAraTrS1cR",
    "outputId": "f0f43d98-b181-4051-d061-84ee4e19fb9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference mode                                                    | time       | speedup (baseline/mode)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.compile()                                                   |       0.04 | -\n",
      "torch.compile() with mode=\"max-autotune\"                          |       0.04 | 1.00x\n",
      "torch.compile() with mode=\"max-autotune-no-cudagraphs\"            |       0.04 | 0.99x\n"
     ]
    }
   ],
   "source": [
    "res_comp_gpu_long = measure_inference_time(compiled_model_gpu, long_inputs_gpu, 1000)\n",
    "\n",
    "res_comp_cuda_gpu_long = measure_inference_time(\n",
    "    compiled_model_with_cudagraphs, long_inputs_gpu, 1000\n",
    ")\n",
    "\n",
    "res_comp_dynamic_gpu_long = measure_inference_time(\n",
    "    compiled_model_dynamic, long_inputs_gpu, 1000\n",
    ")\n",
    "\n",
    "print(f\"{'inference mode':65} | {'time':10} | speedup (baseline/mode)\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"{'torch.compile()':65} | {res_comp_gpu_long:10.2f} | -\")\n",
    "print(\n",
    "    f\"{'torch.compile() with mode=\"max-autotune\"':65} | {res_comp_cuda_gpu_long:10.2f} | {res_comp_gpu_long / res_comp_cuda_gpu_long:.2f}x\"\n",
    ")\n",
    "print(\n",
    "    f\"{'torch.compile() with mode=\"max-autotune-no-cudagraphs\"':65} | {res_comp_dynamic_gpu_long:10.2f} | {res_comp_gpu_long / res_comp_dynamic_gpu_long:.2f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qLqboU8PJmY"
   },
   "source": [
    "**Comment:** For a longer input there seems to be no speedup compared to the compiled model. The inference is slightly longer than for the shorter inputs which is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvDADQe7RRD2"
   },
   "source": [
    "## Changing numerical precision - Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pVYqlvZuRTus",
    "outputId": "436001e5-ce1f-4dd7-981d-4abec07073db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device capability: (7, 5)\n",
      "Tensor Cores available: fast float16 supported.\n"
     ]
    }
   ],
   "source": [
    "# checking if NVidia GPU supports fast float16 (via Tensor Cores)\n",
    "import torch\n",
    "\n",
    "capability = torch.cuda.get_device_capability()\n",
    "print(f\"CUDA device capability: {capability}\")\n",
    "\n",
    "# Tensor Cores are available on NVidia GPUs with CUDA >= 7 (e.g. Volta, Turing, Ampere, Hopper)\n",
    "if capability >= (7, 0):\n",
    "    print(\"Tensor Cores available: fast float16 supported.\")\n",
    "else:\n",
    "    print(\"Tensor Cores not available: float16 may be slow or unsupported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZxzFUa3yjSA5",
    "outputId": "d5df5250-14a4-4522-83d6-d6d72b990f14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of model parameters: torch.float32\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(model_name).to(\"cuda\")\n",
    "print(f\"Data type of model parameters: {model.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "G1qGtRq7bwo2"
   },
   "outputs": [],
   "source": [
    "# casting model weights and inputs to half-precision:\n",
    "model_half = model.half().to(\"cuda\")\n",
    "\n",
    "input_ids = inputs_gpu[\"input_ids\"]\n",
    "attention_mask = inputs_gpu[\"attention_mask\"]\n",
    "\n",
    "# this didn't work\n",
    "# input_ids_half = input_ids.to('cuda').half()\n",
    "# attention_half = attention_mask.to('cuda').half()\n",
    "\n",
    "outputs = model_half(**inputs_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZVN2lrUb14T",
    "outputId": "3c6c8e24-5e8c-4b7f-ab90-87e586ce20a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of model parameters: torch.float16\n",
      "Data type of inputs: torch.int64, torch.int64\n",
      "Data type of model_half parameters: torch.float16\n"
     ]
    }
   ],
   "source": [
    "# verify\n",
    "print(f\"Data type of model parameters: {model.dtype}\")\n",
    "print(f\"Data type of inputs: {input_ids.dtype}, {attention_mask.dtype}\")\n",
    "print(f\"Data type of model_half parameters: {model_half.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxw7P9kcj_cC"
   },
   "source": [
    "- `model` also gets altered by running `.half()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tpXmCdLroErW",
    "outputId": "c799b1a2-3688-4511-9aaa-285a45372334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of model parameters: torch.float32\n",
      "Data type of model_half parameters: torch.float16\n"
     ]
    }
   ],
   "source": [
    "# reinitalise the model bcs model.half works inplace\n",
    "model = AutoModel.from_pretrained(model_name).to(\"cuda\")\n",
    "print(f\"Data type of model parameters: {model.dtype}\")\n",
    "print(f\"Data type of model_half parameters: {model_half.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqgy7PfvkHxC"
   },
   "source": [
    "Inference time comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ou_lLZ9el2Zu"
   },
   "outputs": [],
   "source": [
    "def measure_autocast_inference_time(model, inputs, n_runs):\n",
    "    start = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            for _ in range(n_runs):\n",
    "                _ = model(**inputs)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    return (end - start) / n_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIMNk_Z5kHLm",
    "outputId": "734a4020-752a-4962-fe68-930a28400484"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0147691011428833"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warm-up runs\n",
    "measure_inference_time(model, inputs_gpu, 10)\n",
    "measure_inference_time(model_half, inputs_gpu, 10)\n",
    "measure_autocast_inference_time(model, inputs_gpu, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDW9xasWoacf",
    "outputId": "7b073dc7-f04b-4967-c037-eef68844a755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model                                                             | time       | speedup (baseline/mode)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "float32 model                                                     |       0.04 | -\n",
      "float16 model                                                     |       0.01 | 3.15x\n",
      "float32 model with autocast                                       |       0.02 | 2.53x\n"
     ]
    }
   ],
   "source": [
    "res_model32 = measure_inference_time(model, inputs_gpu, 1000)\n",
    "res_model_half = measure_inference_time(model_half, inputs_gpu, 1000)\n",
    "res_model_autocast = measure_autocast_inference_time(model, inputs_gpu, 1000)\n",
    "\n",
    "print(f\"{'model':65} | {'time':10} | speedup (baseline/mode)\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"{'float32 model':65} | {res_model32:10.2f} | -\")\n",
    "print(\n",
    "    f\"{'float16 model':65} | {res_model_half:10.2f} | {res_model32 / res_model_half:.2f}x\"\n",
    ")\n",
    "print(\n",
    "    f\"{'float32 model with autocast':65} | {res_model_autocast:10.2f} | {res_model32 / res_model_autocast:.2f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhbByuBqPol1"
   },
   "source": [
    "**Comment:**\n",
    "- The static half-precision (16float) model on GPU allows for a speedup of ~3x as compared to inference using the 32float precision model on GPU. This makes it the largest improvement observed in this lab.\n",
    "- The autocast model allows for a slightly lower speedup of ~2.5x, so slightly lower than the static cast. However, there is a trade-off, bacuse autocast allows for mixed precision operations, which might allow for better accuracy/performance since more precise operations are done using higher precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0F3iUB0RdJj"
   },
   "source": [
    "## ONNX - Exercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "3P-wmmZZRhaq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0159ad33dbbe43ca8fc6096670f03cb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02d164585b814294bdc4675592dd2880": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0c620464c043466eaf80ec9c31d0fb75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0cbbda432c5144d3b30a8ee1b633eb21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "12a234c6c0bf4c3987d097cf0f7767a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab52630fa2994dfe82e6480c94828289",
      "placeholder": "​",
      "style": "IPY_MODEL_48920fdbd59c44f58d8b9d7b6d6096a8",
      "value": " 232k/? [00:00&lt;00:00, 8.28MB/s]"
     }
    },
    "15f6d2cbef09479c953aa503aaaf4c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "170294604c5d4a2cb206a6ab5c1c5642": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e6a9ecb5bbe4d5b9ba2a88f18037ace",
       "IPY_MODEL_a9c45abd114f42909257c41381f172b0",
       "IPY_MODEL_40d66fa92f084e29b055add1ce5682c8"
      ],
      "layout": "IPY_MODEL_33a7d60640c147088c708b0add2688b2"
     }
    },
    "1b94d56dea114d06bcf821dd0a005866": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22fee1031b8d4ca9a77a23d813fd31ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dee930f1ee15454083c279eb16d33c9c",
      "placeholder": "​",
      "style": "IPY_MODEL_540d70afdd4b4dc5b91129fc8e5c4efd",
      "value": " 239/239 [00:00&lt;00:00, 22.5kB/s]"
     }
    },
    "254d499cf20243f9a497e79a79510da3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fafaeed688444e68783845e3e4746d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "303e9ff1399f482fb5e4f73a0a598a8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "33a7d60640c147088c708b0add2688b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34f29e63a0a7407392a2b6bcca9ac218": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36ccc56f32914857b6d8bf3b39dcaa73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "40d66fa92f084e29b055add1ce5682c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15f6d2cbef09479c953aa503aaaf4c7d",
      "placeholder": "​",
      "style": "IPY_MODEL_1b94d56dea114d06bcf821dd0a005866",
      "value": " 438M/438M [00:02&lt;00:00, 259MB/s]"
     }
    },
    "4106d763fa1f43a8bf78d49ab6d9f302": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41e4e498c07e46eab9abbed4a88eba3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4664f0cc7cac4322a8f25e1e6fca6705": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6296b8bf39e247feb9faf52449d2f4a6",
      "max": 363,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36ccc56f32914857b6d8bf3b39dcaa73",
      "value": 363
     }
    },
    "48920fdbd59c44f58d8b9d7b6d6096a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "495be958ba3342fe878c6feefad0849c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4de2e289ceec4ab3bbe76366ff673b62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ef8039541ca46448df43e1a516a70e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3994c53068f46ab96bc1d0681d6030e",
      "placeholder": "​",
      "style": "IPY_MODEL_0c620464c043466eaf80ec9c31d0fb75",
      "value": " 466k/? [00:00&lt;00:00, 26.7MB/s]"
     }
    },
    "507db3264a9845689af9b0cc5d6abbf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "523aa6909f3148a1a6657d4132295491": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5267a9c4e6394a7f9edbff6660e43f14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52cd2df4f41e435b99ac88190fa824af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "540d70afdd4b4dc5b91129fc8e5c4efd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54bb2daa3156465a8adf02937a76ef0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "55414364af384b75af725fce2a5ab594": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4de2e289ceec4ab3bbe76366ff673b62",
      "placeholder": "​",
      "style": "IPY_MODEL_507db3264a9845689af9b0cc5d6abbf0",
      "value": "tokenizer.json: "
     }
    },
    "58e48aa8b2d74b31a28edd3b9f5ed107": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "596ec35ac62f4b97ae9d7310bfe5f7f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59e7cde698554d058762c47e8604bf78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ba56bf079e44b799fa8efec11ffb302": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6296b8bf39e247feb9faf52449d2f4a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6558010fe9ab47ab9a989adde9b807e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bd7e317558f4fe49e115bb1cf1cc687": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e3a6d589d8a04b6eb1d9e3a6d0d5e72e",
       "IPY_MODEL_df55187e97ee421ca70b50a92ec49da9",
       "IPY_MODEL_cacca0f04c4143ee98d2446c2d93a32d"
      ],
      "layout": "IPY_MODEL_70b05bab950d4ed49800f203128d6658"
     }
    },
    "6e6a9ecb5bbe4d5b9ba2a88f18037ace": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6558010fe9ab47ab9a989adde9b807e5",
      "placeholder": "​",
      "style": "IPY_MODEL_8bfcbd335d03430792c502ed76610935",
      "value": "model.safetensors: 100%"
     }
    },
    "70b05bab950d4ed49800f203128d6658": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72a88846744243bf94635ea1310f7b9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "7b2f719222c84b4c92f8bc2c8ce679b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_303e9ff1399f482fb5e4f73a0a598a8a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_02d164585b814294bdc4675592dd2880",
      "value": 1
     }
    },
    "7c4156c884da46fba3d404ffddbca8a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_97424668027d43b8ac6b7bf0314d667b",
       "IPY_MODEL_f922676468b4466eb73b33706f030101",
       "IPY_MODEL_22fee1031b8d4ca9a77a23d813fd31ff"
      ],
      "layout": "IPY_MODEL_f2a4018b56d048b8b5fa60f91b7e02c1"
     }
    },
    "8bfcbd335d03430792c502ed76610935": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97424668027d43b8ac6b7bf0314d667b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4106d763fa1f43a8bf78d49ab6d9f302",
      "placeholder": "​",
      "style": "IPY_MODEL_9ce5926d4d0e45de8e0e33f70bafd104",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "9ce5926d4d0e45de8e0e33f70bafd104": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0aeb0da28884559a272baa62c5cafe0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a243ae54dfb34b2985b0b4a3da523a8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_55414364af384b75af725fce2a5ab594",
       "IPY_MODEL_ad9d34d05f1c46269751082fbcd35227",
       "IPY_MODEL_4ef8039541ca46448df43e1a516a70e1"
      ],
      "layout": "IPY_MODEL_5ba56bf079e44b799fa8efec11ffb302"
     }
    },
    "a3b85d19946d4bf3a5c86921f496dfa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a725900520cc4079ab089ea224947cde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8ae023f80f64dcb8e34f179df4392cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0159ad33dbbe43ca8fc6096670f03cb6",
      "placeholder": "​",
      "style": "IPY_MODEL_0cbbda432c5144d3b30a8ee1b633eb21",
      "value": " 363/363 [00:00&lt;00:00, 31.5kB/s]"
     }
    },
    "a9c45abd114f42909257c41381f172b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a725900520cc4079ab089ea224947cde",
      "max": 437971872,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_523aa6909f3148a1a6657d4132295491",
      "value": 437971872
     }
    },
    "ab52630fa2994dfe82e6480c94828289": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad9d34d05f1c46269751082fbcd35227": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72a88846744243bf94635ea1310f7b9d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_54bb2daa3156465a8adf02937a76ef0c",
      "value": 1
     }
    },
    "c3994c53068f46ab96bc1d0681d6030e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cacca0f04c4143ee98d2446c2d93a32d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59e7cde698554d058762c47e8604bf78",
      "placeholder": "​",
      "style": "IPY_MODEL_a0aeb0da28884559a272baa62c5cafe0",
      "value": " 571/571 [00:00&lt;00:00, 49.9kB/s]"
     }
    },
    "d4c4cd6814974c7bb034e91c6fbbd4a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e7992d3659144c57b986e0dd042c9665",
       "IPY_MODEL_4664f0cc7cac4322a8f25e1e6fca6705",
       "IPY_MODEL_a8ae023f80f64dcb8e34f179df4392cb"
      ],
      "layout": "IPY_MODEL_254d499cf20243f9a497e79a79510da3"
     }
    },
    "dee930f1ee15454083c279eb16d33c9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df55187e97ee421ca70b50a92ec49da9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2fafaeed688444e68783845e3e4746d7",
      "max": 571,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a3b85d19946d4bf3a5c86921f496dfa3",
      "value": 571
     }
    },
    "e1a0aa7fbc4b44c0a243a11b582a3515": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eaffed41a00d4cd68f194f4ddb4539bd",
       "IPY_MODEL_7b2f719222c84b4c92f8bc2c8ce679b3",
       "IPY_MODEL_12a234c6c0bf4c3987d097cf0f7767a3"
      ],
      "layout": "IPY_MODEL_596ec35ac62f4b97ae9d7310bfe5f7f0"
     }
    },
    "e3a6d589d8a04b6eb1d9e3a6d0d5e72e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34f29e63a0a7407392a2b6bcca9ac218",
      "placeholder": "​",
      "style": "IPY_MODEL_ead478ef27e245f3abda293ec6bbad34",
      "value": "config.json: 100%"
     }
    },
    "e6c1e6b857e341989582ccc898679b00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7992d3659144c57b986e0dd042c9665": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_495be958ba3342fe878c6feefad0849c",
      "placeholder": "​",
      "style": "IPY_MODEL_41e4e498c07e46eab9abbed4a88eba3f",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "ead478ef27e245f3abda293ec6bbad34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eaffed41a00d4cd68f194f4ddb4539bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5267a9c4e6394a7f9edbff6660e43f14",
      "placeholder": "​",
      "style": "IPY_MODEL_58e48aa8b2d74b31a28edd3b9f5ed107",
      "value": "vocab.txt: "
     }
    },
    "f2a4018b56d048b8b5fa60f91b7e02c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f922676468b4466eb73b33706f030101": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6c1e6b857e341989582ccc898679b00",
      "max": 239,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_52cd2df4f41e435b99ac88190fa824af",
      "value": 239
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
